{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/tanushreehr/Anomaly-Detection/Anomaly-Detection\n",
      "Please provide the path to your DBeaver SQLite database file.\n",
      "You can find this by right-clicking on your database in DBeaver,\n",
      "selecting 'Edit Connection', and checking the 'Path' field.\n",
      "Error: File not found at \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "def get_dbeaver_db_path():\n",
    "    \"\"\"Ask user for the path to their DBeaver SQLite database\"\"\"\n",
    "    print(\"Please provide the path to your DBeaver SQLite database file.\")\n",
    "    print(\"You can find this by right-clicking on your database in DBeaver,\")\n",
    "    print(\"selecting 'Edit Connection', and checking the 'Path' field.\")\n",
    "    \n",
    "    db_path = input(\"Enter the path to your DBeaver SQLite database: \")\n",
    "    \n",
    "    # Validate the path\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"Error: File not found at {db_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Verify it's a SQLite database\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"PRAGMA database_list\")\n",
    "        conn.close()\n",
    "        return db_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_zip_if_needed(zip_file_path, extract_to=None):\n",
    "    \"\"\"Extract ZIP file if data folder doesn't exist\"\"\"\n",
    "    if extract_to is None:\n",
    "        extract_to = os.path.dirname(zip_file_path)\n",
    "    \n",
    "    data_folder = os.path.join(extract_to, 'data')\n",
    "    \n",
    "    # Check if data folder already exists\n",
    "    if os.path.exists(data_folder) and os.path.isdir(data_folder):\n",
    "        csv_files = glob.glob(os.path.join(data_folder, \"*.csv\"))\n",
    "        if csv_files:\n",
    "            print(f\"Data folder already exists with {len(csv_files)} CSV files\")\n",
    "            return data_folder\n",
    "    \n",
    "    # Extract the ZIP file\n",
    "    print(f\"Extracting {zip_file_path} to {extract_to}...\")\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(\"Extraction completed successfully\")\n",
    "        \n",
    "        # Check if data folder exists after extraction\n",
    "        if os.path.exists(data_folder) and os.path.isdir(data_folder):\n",
    "            csv_files = glob.glob(os.path.join(data_folder, \"*.csv\"))\n",
    "            print(f\"Extracted {len(csv_files)} CSV files to {data_folder}\")\n",
    "            return data_folder\n",
    "        else:\n",
    "            # Look for any CSV files in the extracted content\n",
    "            csv_files = []\n",
    "            for root, dirs, files in os.walk(extract_to):\n",
    "                for file in files:\n",
    "                    if file.endswith('.csv'):\n",
    "                        csv_files.append(os.path.join(root, file))\n",
    "            \n",
    "            if csv_files:\n",
    "                print(f\"Found {len(csv_files)} CSV files in {extract_to}\")\n",
    "                # Return the directory containing the CSV files\n",
    "                return os.path.dirname(csv_files[0])\n",
    "            else:\n",
    "                print(\"No CSV files found in the extracted content\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting ZIP file: {e}\")\n",
    "        return None\n",
    "\n",
    "def import_csv_to_smart_logs(db_path, csv_file, chunk_size=10000):\n",
    "    \"\"\"Import CSV data to the smart_logs table in chunks\"\"\"\n",
    "    print(f\"Importing {csv_file} to smart_logs table...\")\n",
    "    \n",
    "    # Connect to SQLite\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Check if smart_logs table exists\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='smart_logs'\")\n",
    "    if not cursor.fetchone():\n",
    "        print(\"Error: smart_logs table doesn't exist in the database!\")\n",
    "        conn.close()\n",
    "        return False\n",
    "    \n",
    "    # Total rows processed\n",
    "    total_rows = 0\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Process file in chunks to avoid memory issues\n",
    "    for chunk in pd.read_csv(csv_file, chunksize=chunk_size):\n",
    "        # Convert data types if needed\n",
    "        for col in chunk.columns:\n",
    "            if col in ['date', 'serial_number', 'model']:\n",
    "                continue\n",
    "            \n",
    "            if chunk[col].dtype == 'object':\n",
    "                try:\n",
    "                    chunk[col] = pd.to_numeric(chunk[col], errors='coerce')\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Insert data into smart_logs table\n",
    "        chunk.to_sql('smart_logs', conn, if_exists='append', index=False)\n",
    "        \n",
    "        # Update row count\n",
    "        total_rows += len(chunk)\n",
    "        print(f\"  Processed {total_rows} rows so far...\")\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Completed importing {csv_file}: {total_rows} rows in {duration:.2f} seconds\")\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # Get project root directory\n",
    "    project_dir = os.getcwd()\n",
    "    print(f\"Current working directory: {project_dir}\")\n",
    "    \n",
    "    # Get DBeaver database path\n",
    "    db_path = get_dbeaver_db_path()\n",
    "    if not db_path:\n",
    "        return\n",
    "    \n",
    "    # Look for ZIP file\n",
    "    zip_file_path = os.path.join(project_dir, 'data_Q1_2018.zip')\n",
    "    if os.path.exists(zip_file_path):\n",
    "        # Extract the ZIP file\n",
    "        data_folder = extract_zip_if_needed(zip_file_path, project_dir)\n",
    "    else:\n",
    "        # Look for data folder\n",
    "        data_folder = os.path.join(project_dir, 'data')\n",
    "        if not os.path.exists(data_folder):\n",
    "            print(f\"Data folder not found: {data_folder}\")\n",
    "            # Ask user for data folder path\n",
    "            data_folder = input(\"Please enter the path to your data folder: \")\n",
    "            if not os.path.exists(data_folder):\n",
    "                print(f\"Path not found: {data_folder}\")\n",
    "                return\n",
    "    \n",
    "    # Find all CSV files in the data folder\n",
    "    csv_files = glob.glob(os.path.join(data_folder, \"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {data_folder}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files in {data_folder}\")\n",
    "    \n",
    "    # Import each file to smart_logs table\n",
    "    success_count = 0\n",
    "    for i, csv_file in enumerate(csv_files, 1):\n",
    "        print(f\"Processing file {i}/{len(csv_files)}: {os.path.basename(csv_file)}\")\n",
    "        try:\n",
    "            if import_csv_to_smart_logs(db_path, csv_file):\n",
    "                success_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_file}: {e}\")\n",
    "    \n",
    "    print(f\"Import complete: Successfully imported {success_count} out of {len(csv_files)} files\")\n",
    "    \n",
    "    # Create indexes if they don't exist\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(\"Creating indexes for faster querying (if they don't exist)...\")\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_serial_number ON smart_logs (serial_number)')\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_date ON smart_logs (date)')\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_failure ON smart_logs (failure)')\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_model ON smart_logs (model)')\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(\"Indexes created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating indexes: {e}\")\n",
    "    \n",
    "    print(f\"Database '{db_path}' is now ready for analysis\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
